# Awesome-LLM-for-RecSys

Generally two advantages:
1. Open-world knowledge embedded in the pre-trained parameters
    - Textual encoder
    - Reasoning ability
3. Textual features as the unified language to bridge different recommendation domains

Dataset Survey & Benchmarks

## LLM for Feature Engineering

## LLM as Feature Encoder

| **Paper** | **Publication** | **Encoded Feature** | **Link** |
|:---|:---:|:---:|:---:|
| U-BERT: Pre-training User Representations for Improved Recommendation | AAAI 2021 | User | [[Link]](https://ojs.aaai.org/index.php/AAAI/article/view/16557) |
|  |  |  |  |
| UNBERT: User-News Matching BERT for News Recommendation | IJCAI 2021 | Item | [[Link]](https://www.ijcai.org/proceedings/2021/462) |
| Pre-trained Language Model based Ranking in Baidu Search | KDD 2021 | Item | [[Link]](https://arxiv.org/abs/2105.11108) |
| Pre-trained Language Model for Web-scale Retrieval in Baidu Search | KDD 2021 | Item | [[Link]](https://arxiv.org/abs/2106.03373) |
| Empowering News Recommendation with Pre-trained Language Models | SIGIR 2021 | Item | [[Link]](https://arxiv.org/abs/2104.07413) |
| Towards Universal Sequence Representation Learning for Recommender Systems | KDD 2022 | Item | [[Link]](https://arxiv.org/abs/2206.05941) |
| Boosting Deep CTR Prediction with a Plug-and-Play Pre-trainer for News Recommendation | COLING 2022 | Item | [[Link]](https://aclanthology.org/2022.coling-1.249/) |
| MM-Rec: Visiolinguistic Model Empowered Multimodal News Recommendation | SIGIR 2022 | Item | [[Link]](https://dl.acm.org/doi/abs/10.1145/3477495.3531896) |
| Tiny-NewsRec: Effective and Efficient PLM-based News Recommendation | EMNLP 2022 | Item | [[Link]](https://arxiv.org/abs/2112.00944) |
| TwHIN-BERT: A Socially-Enriched Pre-trained Language Model for Multilingual Tweet Representations | Arxiv 2022 | Item | [[Link]](https://arxiv.org/abs/2209.07562) |
| Learning Vector-Quantized Item Representation for Transferable Sequential Recommenders | WWW 2023 | Item | [[Link]](https://arxiv.org/abs/2210.12316) |
|  |  |  |
| CTR-BERT: Cost-effective knowledge distillation for billion-parameter teacher models | ENLSP 2021 | User & Item | [[Link]](https://neurips2021-nlp.github.io/papers/20/CameraReady/camera_ready_final.pdf) |


## LLM as Core Recommender Model

| **Paper** | **Publication** | **Link** |
|:---|:---:|:---:|
| Language Models as Recommender Systems: Evaluations and Limitations | ICBINB 2021 | [[Link]](https://openreview.net/forum?id=hFx3fY7-m9b) |
| PTM4Tag: Sharpening Tag Recommendation of Stack Overflow Posts with Pre-trained Models | ICPC 2022 | [[Link]](https://arxiv.org/abs/2203.10965) |
| M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender Systems | Arxiv 2022 | [[Link]](https://arxiv.org/abs/2205.08084) |
| PTab: Using the Pre-trained Language Model for Modeling Tabular Data | Arxiv 2022 | [[Link]](https://arxiv.org/abs/2209.08060) |
|  |  |  |
| Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5) | RecSys 2022 | [[Link]](https://arxiv.org/abs/2203.13366) |
| GPT4Rec: A Generative Framework for Personalized Recommendation and User Interests Interpretation | Arxiv 2023 | [[Link]](https://arxiv.org/abs/2304.03879) |
| Zero-Shot Recommendation as Language Modeling | Arxiv 2023 | [[Link]](https://arxiv.org/abs/2112.04184) |
| How to Index Item IDs for Recommendation Foundation Models | Arxiv 2023 | [[Link]](https://arxiv.org/abs/2305.06569) |
| Recommender Systems with Generative Retrieval | Arxiv 2023 | [[Link]](https://arxiv.org/abs/2305.05065) |
| TabLLM: Few-shot Classification of Tabular Data with Large Language Models | AISTATS 2023 | [[Link]](https://arxiv.org/abs/2210.10723) |

## LLM as RS Pipeline Controller

| **Paper** | **Publication** | **Code** |
|:---:|:---:|:---:|
|  |  |  |



